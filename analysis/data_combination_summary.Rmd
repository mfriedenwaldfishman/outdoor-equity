---
title: "Data Cleaning"
author: "Clarissa Boyajian and Halina Do-Linh"
date: "1/24/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(janitor)
library(lubridate)
library(sf)
library(tidycensus)
library(patchwork)
library(scales)
library(tmap)

options(scipen = 999)


# RIDB functions
# raw data
source("functions/function_ridb_subset-pre2018.R")
source("functions/function_ridb_subset-post2019.R")
# clean data and calculate variables
source("functions/function_ridb_variable_calculate-pre2018.R")
# standardize values
# need to make function still

# ACS functions
source("functions/function_acs_race.R")
source("functions/function_acs_median_income.R")
source("functions/function_acs_transportation.R")
source("functions/function_acs_education.R")
```

# Geometries

```{r, eval=FALSE}
## use acs to get county and state geometries ##
```


# RIDB - read in data, calculate varibales, standardize values

```{r}
## 2018
# read in data
RIDB_subset_pre2018(full_file_path = "../../data_raw/reservations2018.csv", 
                    state_abbrev = "CA", year = 2018)
# calculate variables
RIDB_calculate_pre2018(input_df_name = data_ridb_2018, output_df_name = "data_ridb_2018")
## create function to standardize values (or add to calculate function)
```


# Census Data - api set up, read, subset, calculate values

```{r message=FALSE}
# api set up

# # ONLY HAVE TO RUN THE FIRST TIME USING THIS RMD on a new machine
# census_api <- source("private/census-api.R")
# census_api_key(key = census_api[[1]], install = TRUE, overwrite = TRUE)
# # run in console:
## readRenviron("~/.Renviron")

# look at option variables
#View(load_variables(2018, "acs5", cache = TRUE))

```

```{r}
# read in census data
acs_subset_calculate_race(geography = "zcta", year = 2018, state = NULL)
acs_subset_calculate_median_income(geography = "zcta", year = 2018, state = NULL)
acs_subset_calculate_transportation(geography = "zcta", year = 2018, state = NULL)
acs_subset_calculate_education(geography = "zcta", year = 2018, state = NULL)
```



# Join RIDB and Census

```{r}
data_combined_2018 <- 
  left_join(x = data_ridb_2018,
            y = data_acs_2018_race_percent,
            by = c("customer_zip" = "zip_code")) %>% 
  left_join(y = data_acs_2018_education_percent,
            by = c("customer_zip" = "zip_code")) %>% 
  left_join(y = data_acs_2018_median_income,
            by = c("customer_zip" = "zip_code")) %>% 
  left_join(y = data_acs_2018_transportation_percent,
            by = c("customer_zip" = "zip_code"))
```


# RIDB - site summary

Aggregate (median) to reservable site level
```{r}
data_combined_2018_site_summary <- 
  data_combined_2018 %>% 
  filter(daily_cost_per_visitor != "Inf") %>% #drop 48 rows with "Inf" for cost/visitor/day
  group_by(agency, park) %>% 
  summarize(median_paid = median(total_paid),
            max_paid = max(total_paid),
            min_paid = min(total_paid),
            median_number_of_people = median(number_of_people),
            max_number_of_people = max(number_of_people),
            min_number_of_people = min(number_of_people),
            median_length_of_stay = median(length_of_stay),
            max_length_of_stay = max(length_of_stay),
            min_length_of_stay = min(length_of_stay),
            median_booking_window = median(booking_window),
            max_booking_window = max(booking_window),
            min_booking_window = min(booking_window),
            median_daily_cost_per_visitor = median(daily_cost_per_visitor),
            max_daily_cost_per_visitor = max(daily_cost_per_visitor),
            min_daily_cost_per_visitor = min(daily_cost_per_visitor),
            # na.rm drops ~3% of data (missing ZIP codes from acs5)
            median_median_income = median(median_income, na.rm = TRUE),
            max_median_income = max(median_income, na.rm = TRUE),
            min_median_income = min(median_income, na.rm = TRUE),
            median_percent_asian = median(asian, na.rm = TRUE),
            median_percent_black = median(black, na.rm = TRUE),
            median_percent_multiracial = median(multiracial, na.rm = TRUE),
            median_percent_other = median(other, na.rm = TRUE),
            median_percent_white = median(white, na.rm = TRUE),
            median_percent_pacific_islander = median(pacific_islander, na.rm = TRUE),
            median_percent_native_american = median(native_american, na.rm = TRUE),
            median_hispanic_latinx = median(hispanic_latinx, na.rm = TRUE),
            median_college = median(college, na.rm = TRUE),
            median_hs_GED_or_below = median(hs_GED_or_below, na.rm = TRUE),
            median_master_or_above = median(master_or_above, na.rm = TRUE),
            median_some_college = median(some_college, na.rm = TRUE),
            median_no_vehicle = median(no_vehicle, na.rm = TRUE),
            # include count column listing number of reservations for each park
            count = n())
```


## Save to CSV
*geometries breaking write to CSV*
```{r}
write.csv(x = data_combined_2018, "../../../data_clean/2018_joined_data.csv", row.names = FALSE)

write.csv(x = data_combined_2018_site_summary, "../../../data_clean/2018_joined_data_site_summary.csv", row.names = FALSE)
```



```{r, eval=FALSe}
# # small version of data for Will and Soyoung
# data_combined_2018_small <- head(data_combined_2018, 100)
# write.csv(x = data_combined_2018_small, "../../../data_clean/2018_joined_data_smallSubset.csv", row.names = FALSE)
```



